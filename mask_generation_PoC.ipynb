{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d889b14f",
   "metadata": {},
   "source": [
    "Quick and VERY dirty mask-generation >.>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7de73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import transforms as transforms\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import seaborn_image as isns\n",
    "from PIL import Image\n",
    "from typing import Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aeb97d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_names = [\n",
    "    '__background__', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "    'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'N/A', 'stop sign',\n",
    "    'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "    'elephant', 'bear', 'zebra', 'giraffe', 'N/A', 'backpack', 'umbrella', 'N/A', 'N/A',\n",
    "    'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball',\n",
    "    'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
    "    'bottle', 'N/A', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
    "    'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza',\n",
    "    'donut', 'cake', 'chair', 'couch', 'potted plant', 'bed', 'N/A', 'dining table',\n",
    "    'N/A', 'N/A', 'toilet', 'N/A', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "    'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'N/A', 'book',\n",
    "    'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52882039",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths = [ \"img/0001.jpg\", \"img/0108.jpg\", \"img/0115.jpg\", \"img/0150.jpg\"]\n",
    "threshold = 0.965"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0111bb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will help us create a different color for each class\n",
    "COLORS = np.random.uniform(0, 255, size=(len(coco_names), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ee094fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_outputs(image, model, threshold):\n",
    "    with torch.no_grad():\n",
    "        # forward pass of the image through the model\n",
    "        outputs = model(image)\n",
    "    \n",
    "    # get all the scores\n",
    "    scores = list(outputs[0]['scores'].detach().cpu().numpy())\n",
    "    # index of those scores which are above a certain threshold\n",
    "    thresholded_preds_inidices = [scores.index(i) for i in scores if i > threshold]\n",
    "    thresholded_preds_count = len(thresholded_preds_inidices)\n",
    "    # get the masks\n",
    "    masks = (outputs[0]['masks']>0.5).squeeze().detach().cpu().numpy()\n",
    "    # discard masks for objects which are below threshold\n",
    "    masks = masks[:thresholded_preds_count]\n",
    "    # get the bounding boxes, in (x1, y1), (x2, y2) format\n",
    "    boxes = [[(int(i[0]), int(i[1])), (int(i[2]), int(i[3]))]  for i in outputs[0]['boxes'].detach().cpu()]\n",
    "    # discard bounding boxes below threshold value\n",
    "    boxes = boxes[:thresholded_preds_count]\n",
    "    # get the classes labels\n",
    "    labels = [coco_names[i] for i in outputs[0]['labels']]\n",
    "    return masks, boxes, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19074639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(image, masks, boxes, labels):\n",
    "    alpha = 1 \n",
    "    beta = 0.6 # transparency for the segmentation map\n",
    "    gamma = 0 # scalar added to each sum\n",
    "    w, h = image.size\n",
    "    #Might not be needed\n",
    "    segmentation_map = np.zeros((h,w,3))\n",
    "    \n",
    "    for i in range(len(masks)):\n",
    "        if labels[i] == 'person':\n",
    "            #can we clean this more up?\n",
    "            red_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            green_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            blue_map = np.zeros_like(masks[i]).astype(np.uint8)\n",
    "            color = (255,255,255)\n",
    "            red_map[masks[i] == 1], green_map[masks[i] == 1], blue_map[masks[i] == 1]  = color\n",
    "            segmentation_map = np.stack([red_map, green_map, blue_map], axis=2)\n",
    "            \n",
    "    return segmentation_map\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c81d8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=0.0)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=0.0)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=0.0)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=0.0)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=0.0)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (2): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        (3): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       "    )\n",
       "    (mask_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(14, 14), sampling_ratio=2)\n",
       "    (mask_head): MaskRCNNHeads(\n",
       "      (mask_fcn1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu1): ReLU(inplace=True)\n",
       "      (mask_fcn2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu2): ReLU(inplace=True)\n",
       "      (mask_fcn3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu3): ReLU(inplace=True)\n",
       "      (mask_fcn4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (relu4): ReLU(inplace=True)\n",
       "    )\n",
       "    (mask_predictor): MaskRCNNPredictor(\n",
       "      (conv5_mask): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (mask_fcn_logits): Conv2d(256, 91, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the model\n",
    "model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True, progress=True, \n",
    "                                                           num_classes=91)\n",
    "# set the computation device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# load the modle on to the computation device and set to eval mode\n",
    "model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "268e0a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform to convert the image to tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88c6a340",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nea/miniconda3/envs/work-env/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  /Users/distiller/project/conda/conda-bld/pytorch_1639180852547/work/aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    }
   ],
   "source": [
    "masked_images = []\n",
    "for img_path in image_paths:\n",
    "    image = Image.open(img_path)\n",
    "    # keep a copy of the original image for OpenCV functions and applying masks\n",
    "    orig_image = image.copy()\n",
    "    # transform the image\n",
    "    image = transform(image)\n",
    "    # add a batch dimension\n",
    "    image = image.unsqueeze(0).to(device)\n",
    "    a = time.time()\n",
    "    masks, boxes, labels = get_outputs(image, model, threshold)\n",
    "    output_img = create_mask(orig_image, masks, boxes, labels)\n",
    "    masked_images.append(output_img)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "003552f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlen = len(masked_images)\n",
    "fig, axes = plt.subplots(1, xlen)\n",
    "fig.set_size_inches(20,10)\n",
    "for ax, img in zip(axes, masked_images):\n",
    "    isns.imgplot(img, ax=ax, cbar=False)\n",
    "    ax.invert_yaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37248b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = Image.open(\"img/0001.jpg\")\n",
    "w, h = image.size\n",
    "result = np.zeros((h,w,3))\n",
    "for mask in masked_images:\n",
    "    result = cv2.add(result, mask,dtype=cv2.CV_64F)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b3fdcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x14880df40>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Ik is heads-down but really no time to fix this rn, we wont need it anyway\n",
    "plt.imshow(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83aca18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-env-kernel",
   "language": "python",
   "name": "work-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
