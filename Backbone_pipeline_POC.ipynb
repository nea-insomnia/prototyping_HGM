{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97c9bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import image_similarity_measures\n",
    "from image_similarity_measures.quality_metrics import metric_functions\n",
    "from itertools import combinations\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn_image as isns\n",
    "from PIL import Image, ImageOps\n",
    "import glob\n",
    "import sys, os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66bb8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VAR declarations\n",
    "#TODO manage this via config\n",
    "all_metrics =  ['sre']\n",
    "#maximum number of frames to capture\n",
    "#max_frames = 150\n",
    "comparison_images = {}\n",
    "keyframes = []\n",
    "max_keyframes = 4\n",
    "\n",
    "parent_dir = \"data/\"\n",
    "video_path = \"data/videos/\"\n",
    "test_video = 'testvid.mov'\n",
    "\n",
    "user_id = \"0042\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3be88995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/0042_input\n",
      "Folder already exists. Skipping..\n",
      "data/0042_mask\n",
      "Folder already exists. Skipping..\n",
      "data/0042_models\n",
      "Folder already exists. Skipping..\n",
      "data/0042_output\n",
      "Folder already exists. Skipping..\n",
      "data/0042_target\n",
      "Folder already exists. Skipping..\n"
     ]
    }
   ],
   "source": [
    "#create necessary dictionaries\n",
    "def create_folder_structure(user_id: str):\n",
    "    #Create folder structure for new dataset and export names to .json file for further usage\n",
    "\n",
    "    folder_dict = {\n",
    "                \"input\": f\"{user_id}_input\",\n",
    "                \"mask\": f\"{user_id}_mask\", \n",
    "                \"models\": f\"{user_id}_models\",\n",
    "                \"output\": f\"{user_id}_output\",\n",
    "                \"target\": f\"{user_id}_target\"\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for key, directory in list(folder_dict.items()):\n",
    "        path = os.path.join(parent_dir,directory)\n",
    "        print(path)\n",
    "        try:\n",
    "            os.mkdir(path)\n",
    "            print(f\"{directory} successfully created\")\n",
    "        except OSError as error:\n",
    "            print(\"Folder already exists. Skipping..\")\n",
    "\n",
    "        #add parent_dict to .json. This is necessary for keeping flexibility if refactoring is necessary\n",
    "        folder_dict[\"ParentDir\"] = parent_dir\n",
    "        with open (\"folderstructure.json\",\"w\") as f:\n",
    "            json.dump(folder_dict,f)\n",
    "\n",
    "\n",
    "create_folder_structure(user_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20e955aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neas video\n",
    "#cap = cv2.VideoCapture('testvid.mov')\n",
    "#Richards video\n",
    "cap = cv2.VideoCapture(f\"{video_path}{test_video}\")\n",
    "#Or most common ID for webcams:\n",
    "#cap = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f425dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frames per second using video.get(cv2.CAP_PROP_FPS) : 30.029060381013885\n"
     ]
    }
   ],
   "source": [
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "print(f\"Frames per second using video.get(cv2.CAP_PROP_FPS) : {fps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e437fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add all frames as we'll need them later\n",
    "#Maybe some padding for frame_name\n",
    "\n",
    "frame_nr = 0\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        #TODO: change the filename like ffmpeg ones if we split the video into images\n",
    "        frame_name = f\"frame_{frame_nr}.jpg\" \n",
    "        cv2.imwrite(f\"{parent_dir}{user_id}_input/{frame_name}\",frame)\n",
    "    else:\n",
    "        cap.release()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a382d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO ensure min_frames, max_frames for comparison pool\n",
    "\n",
    "frame_nr = 0\n",
    "#TODO ensure how to handle exceptions\n",
    "#TODO add all frames/framenames somewhere as we'l need them later\n",
    "#TODO ensure max_len of video or the pre-selection must be adapted\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        #TODO: change the filename like ffmpeg ones if we split the video into images\n",
    "        frame_name = f\"frame_{frame_nr}.jpg\" \n",
    "        cv2.imwrite(f\"{parent_dir}{user_id}_input/{frame_name}\",frame)\n",
    "        #print(frame_name)\n",
    "        #cv2.imwrite(f\"frame{frame_nr}.jpg\", frame)\n",
    "        #i.e. at 30 fps, this advances one second\n",
    "        #int(fps) for rounding\n",
    "        frame_nr += int(fps)\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_nr)\n",
    "        comparison_images[frame_name] = frame\n",
    "        #comparison_images.append(tuple([frame_name,frame]))\n",
    "    else:\n",
    "        cap.release()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64f725ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(df: pd.DataFrame, img_name_a: str, img_name_b: str, img_a: np.ndarray, img_b: np.ndarray, metrics: List[str]) -> pd.DataFrame:\n",
    "    for metric in metrics:\n",
    "        metric_func = metric_functions[metric]\n",
    "        start_time = time.time()\n",
    "        out_value = float(metric_func(img_a, img_b))\n",
    "        end_time = time.time()\n",
    "        output_dict = {}\n",
    "        output_dict['metric'] = metric\n",
    "        output_dict['x'] = img_name_a\n",
    "        output_dict['y'] = img_name_b\n",
    "        output_dict['value'] = out_value\n",
    "        output_dict['walltime'] = end_time - start_time\n",
    "        df = df.append(output_dict,ignore_index=True)\n",
    "        output_dict['y'] = img_name_a\n",
    "        output_dict['x'] = img_name_b\n",
    "        df = df.append(output_dict,ignore_index=True)\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74a67ea0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'metric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q0/71ws9rkn6n71wnc8ztzpc8l40000gn/T/ipykernel_23084/3712994517.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomparison_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomparison_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpair\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mplot_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sre'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpivot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplot_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/work-env/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5485\u001b[0m         ):\n\u001b[1;32m   5486\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'metric'"
     ]
    }
   ],
   "source": [
    "#Build some nice plots for better evaluation\n",
    "#Select one metric and pivot the dataframe for creating the heatmap plot\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for pair in combinations(comparison_images.keys(), 2):\n",
    "    #print(pair)\n",
    "    #*pair : instead handing over a tuple(a,b) , hand over each element as separate argument a,b\n",
    "    df = compare(df, *pair, comparison_images[pair[0]], comparison_images[pair[1]], all_metrics)\n",
    "    \n",
    "plot_df = df[df.metric == 'sre'].pivot('x', 'y', 'value')\n",
    "ax = sns.heatmap(plot_df, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da707210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_keyframes(comparison_images: Dict[str,np.ndarray], max_keyframes: int) -> List[np.ndarray]:\n",
    "    \n",
    "    compare_options = list(combinations(comparison_images.keys(), max_keyframes))\n",
    "    compare_df = pd.DataFrame()\n",
    "    \n",
    "    #Calculate and accumalate the values on all 2-combinations of each 4-tuple\n",
    "    #(frame_0, frame_13, frame_60, frame_115)\n",
    "    # metric(frame_0,frame_13) + metric(frame_0,frame_60) +...\n",
    "    for option in compare_options:\n",
    "        value = 0.0\n",
    "        for x, y in combinations(option, 2):\n",
    "            #get the value of the current combination and square it\n",
    "            #add to the final value of the 4-tuple\n",
    "            value += plot_df[x][y] ** 2\n",
    "\n",
    "        compare_df = compare_df.append({\"option\": option, \"value\": value}, ignore_index=True)\n",
    "\n",
    "    # select the 4-tuple with lowest metric value as keyframes\n",
    "    keyframes = list(compare_df.sort_values(by=['value'], ascending=True).iloc[0].option)\n",
    "    \n",
    "    return keyframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b272926",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyframes = select_keyframes(comparison_images, max_keyframes)\n",
    "keyframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792f1829",
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in keyframes:\n",
    "    cv2.imwrite(img_name, comparison_images[img_name])\n",
    "    \n",
    "xlen = len(keyframes)\n",
    "fig, axes = plt.subplots(1, xlen)\n",
    "fig.set_size_inches(20,10)\n",
    "for ax, img_path in zip(axes, keyframes):\n",
    "    img = Image.open(img_path)\n",
    "    isns.imgplot(img, ax=ax, cbar=False)\n",
    "    ax.invert_yaxis()\n",
    "    ax.set_xlabel(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67054047",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "work-env-kernel",
   "language": "python",
   "name": "work-env-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
